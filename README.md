# RAG
Multimodal RAG using imagebind
A multimodal embedding model enables the integration of text, images, and various data types into a single vector space, facilitating cross-modality vector similarity searches within the KDB.AI vector database. A multimodal LLM can then be augmented with retrieved embeddings to generate a response and complete the RAG pipeline.
The multimodal embedding model we will explore is called “ImageBind” which was developed by Meta. ImageBind can embed several data modalities including text, images, video, audio, depth, thermal, and inertial measurement unit (IMU) which includes gyroscope and accelerometer data.

